# Copy to .env and fill values as needed
#
# Ollama (recommended)
OLLAMA_BASE_URL=http://127.0.0.1:11434
# Default chat model is kept SMALL to run on low-RAM machines (e.g. EC2 t2.micro).
# If you have more RAM, you can switch back to a larger model like `llama3.2:1b`.
OLLAMA_CHAT_MODEL=qwen2.5:0.5b
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_TIMEOUT=120
OLLAMA_NUM_PREDICT=256
# Smaller context reduces RAM usage.
OLLAMA_NUM_CTX=1024
OLLAMA_KEEP_ALIVE=5m

# Storage
INDEX_PATH=indexes

# Optional: AWS S3 (best-effort in current code)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_BUCKET_NAME=
AWS_REGION=us-east-1
